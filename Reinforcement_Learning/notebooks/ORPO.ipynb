{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwNxh0pCQhfI",
        "outputId": "e4c288e1-2fa3-4717-d9dd-ae3ec0b91e3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ben/code/smol-course/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        ")\n",
        "from trl import ORPOConfig, ORPOTrainer, setup_chat_format\n",
        "\n",
        "# Authenticate to Hugging Face\n",
        "from huggingface_hub import login\n",
        "\n",
        "login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ju22-PqTdCzm",
        "outputId": "cf02a04e-2d5a-48a0-99b6-366e3f1faad0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 100%|██████████| 62135/62135 [00:00<00:00, 450465.27 examples/s]\n",
            "Generating test split: 100%|██████████| 1000/1000 [00:00<00:00, 382866.64 examples/s]\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(path=\"trl-lib/ultrafeedback_binarized\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2kGBNStQoUd"
      },
      "outputs": [],
      "source": [
        "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "# Model to fine-tune\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    pretrained_model_name_or_path=model_name,\n",
        "    torch_dtype=torch.float32,\n",
        ").to(device)\n",
        "model.config.use_cache = False\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model, tokenizer = setup_chat_format(model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWDwJe7_Qqgb"
      },
      "outputs": [],
      "source": [
        "orpo_args = ORPOConfig(\n",
        "    learning_rate=8e-6,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    max_length=1024,\n",
        "    max_prompt_length=512,\n",
        "    beta=0.1,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    optim=\"paged_adamw_8bit\" if device == \"cuda\" else \"adamw_torch\",\n",
        "    num_train_epochs=1,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=0.2,\n",
        "    logging_steps=1,\n",
        "    warmup_steps=10,\n",
        "    report_to=\"none\",\n",
        "    output_dir=\"./results/\",\n",
        "    use_mps_device=device == \"mps\",\n",
        "    hub_model_id=finetune_name,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxF8H8g_dCzp"
      },
      "outputs": [],
      "source": [
        "trainer = ORPOTrainer(\n",
        "    model=model,\n",
        "    args=orpo_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    processing_class=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5SsBxBIdCzp"
      },
      "outputs": [],
      "source": [
        "trainer.train()  # Train the model\n",
        "\n",
        "# Save the model\n",
        "trainer.save_model(\"OPRO_model\")\n",
        "\n",
        "# Save to the huggingface hub if login (HF_TOKEN is set)\n",
        "if os.getenv(\"HF_TOKEN\"):\n",
        "    trainer.push_to_hub(tags=finetune_tags)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}